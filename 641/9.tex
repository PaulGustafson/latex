\documentclass{article}
\usepackage{../m}

\begin{document}
\noindent Paul Gustafson\\
\noindent Texas A\&M University - Math 641\\ 
\noindent Instructor - Fran Narcowich

\subsection*{HW 9}
\p{1} Finish the proof of the Projection Theorem: If for every $f \in \mH$ there is a $p \in V$ such that $\|p - f\| = \min_{v \in V} \|v - f\|$ the $V$ is closed.

\begin{proof}
Let $(f_n) \subset V$ with $f_n \to f$. Suppose $f \not\in V$.  Let $p$ be the projection of $f$ to $V$.  Then $\|f_n - f\| \ge \|f - p\| > 0$ for all $n$. Letting $n \to \infty$, we get $0 \ge \|f - p \| > 0$,  a contradiction.
\end{proof}

\p 2 If $L : \mH \to \mH$ is a bounded linear transformation, then $\overline{R(L)} = N (L^*)^\perp$.
\begin{proof}
Suppose $(Lv_n)_n \subset  R(L)$ with $Lv_n \to w$.  Then if $u \in N(L^*)$ we have $\langle u, L v_n \rangle = \langle L u , v_n \rangle = 0$. Letting $n \to \infty$, we have $\langle u, w \rangle = 0$.  Hence, $\overline{R(L)} \subset N(L^*)^\perp$.

For the reverse inclusion, suppose $v \in N(L^*)^\perp$.  Let $P$ be the orthogonal projection operator mapping onto $\overline{R(L)}$.  Let $u = v - Pv \in \overline{R(L)}^\perp$. Hence, $0 = \langle L L^* u, u \rangle = \|L^*u\|$, so $L^*u = 0$.  Moreover $v, Pv \in N(L^*)^\perp$, so $u \in N(L^*)^\perp$.   Thus $u = 0$, so $v \in \overline{R(L)}$.
\end{proof}

\p 3 Let $\mH$ be a Hilbert space of functions that are defined on [0,1]. In addition, suppose that $\mH \subset C[0,1]$, with $\|f\|_{C[0,1]} \le K \|f \|_H$ for all $f \in \mH$. (The Sobolev space $H^1$ has this property.)

\begin{enumerate}[a.]
\item Show that the point-evaluation functional $\phi_x(f) = f(x)$ is a bounded linear functional on $\mH$.
\item Let $x$ be fixed. Show that there is a kernel $k(x,y) \in \mH$ such that 
$$ \phi_x(f) = f(x) = \langle f , k(x, \cdot) \rangle$$
(The kernel $k(x,y)$ is called a reproducing kernel and $\mH$ is called a reproducing kernel Hilbert space.)
\item For $x, z$ fixed, show that $k(z,x) = \langle k(z, \cdot), k(x, \cdot) \rangle$. In addition, let $(x_j)_{j=1}^n$ be any finite set of distinct points in $[0,1]$.  Show that the matrix $G_{jk} = k(x_k, x_j)$ is positive semidefinite; that is $\sum_{j,k} c_k \overline{c_j} k(x_k, x_j) \ge 0$.
\item Suppose the matrix $G$ is positive definite and therefore invertible. Let $f \in \mH$. Show that there are unique coefficients $(c_j)_{j=1}^n$ such that $s(x) = \sum_{j=1}^n k(x_j, x) c_j$ interpolates $f$ at the $x_j$'s.
\end{enumerate}

\begin{proof}
For (a), we have $|\phi_x(f)| \le \|f\|_{C[0,1]} \le K \|f\|_{\mH}$.

(b) follows from (a) and the Riesz Representation Theorem.

For (c), we have $k(z,x) = \phi_x(k(z, \cdot)) = \langle k(z, \cdot) , k(x, cdot) \rangle$.  For the other part, we have  
\begin{align*}
\sum_{j,k} c_k \overline{c_j} k(x_k, x_j) & =  \sum_{j,k} c_k \overline{c_j} \langle k(x_k, \cdot) , k(x_j, cdot) \rangle
\\ & =  \sum_{j,k} \langle c_k k(x_k, \cdot) , c_j k(x_j, cdot) \rangle
\\ & =  \left\langle \sum_k c_k k(x_k, \cdot) , \sum_j c_j k(x_j, cdot) \right \rangle
\\ & \ge 0.
\end{align*}

For (d), let $v = (f(x_1), f(x_2), \ldots, f(x_n))$.  A coefficient vector $c$ interpolates $f$ at the $x_j$'s iff it is the solution to the matrix equation $c G = v$. This has a unique solution since $G$ is invertible.
\end{proof}

\p 4 Consider the finite rank (degenerate) kernel $k(x,y) = \phi_1(x) \overline{\psi_1}(y) + \phi_2(x) \overline{\psi_2} (y)$, where $\phi_1 = 2x - 1, \phi_2 = x^2, \psi_1 = 1, \psi_2 = 4x - 3$. Let $Ku = \int_0^1 k(x,y) u(y) dy$. Assume that $L:= I - \lambda K$ has closed range.

\begin{enumerate}[a.]
\item For what values of $\lambda$ does the integral equation
$$u(x) - \lambda \int_0^1 k(x,y) u(y) dy = f(x)$$
have a solution for all $f \in L^2[0,1]$.
\item For these values, find the solution $u = (I - \lambda K)^{-1} F$ -- i.e., find the resolvent.
\item For the values of $\lambda$ for which the equation does not have a solution for all $f$, find a condition on $f$ that guarantees a solution exists. Will the solution be unique?
\end{enumerate}

\begin{proof}
For (a), we have $u - \lambda \sum_i \langle u, \psi_i \rangle \phi_i = f$.  Hence $\langle u, \psi_j \rangle - \sum_i \langle u, \psi_i \rangle \langle \phi_i, \psi_j \rangle = \langle f, \psi_j \rangle$.
Hence $ \sum_i (\delta_{ij}  - \lambda \langle \phi_i, \psi_j \rangle) \langle u, \psi_i \rangle = \langle f, \psi_j \rangle$.
Using the alternative value for $\phi_2$, the determinant of $\delta_{ij} - \lambda \langle \phi_j, \psi_j$ is $1$.  Thus, we can find solutions for all $\lambda$.

For (b), the solution is given by $\langle u, \psi_1 \rangle = \langle f, \psi_1 \rangle + \lambda/3 \langle f, \psi_2 \rangle$ and $\langle u, \psi_2  \rangle = \langle f, \psi_2 \rangle$.

\end{proof}


\p 5 Let $S = \{ (a_j) \in \ell^2 : \sum_j (1+j^2)|a_j|^2 \le 1 \}$. Show that $S$ is a compact subset of $\ell^2$.
\begin{proof}
It suffices to show that $S$ is closed and totally bounded. To see that $S$ is closed, suppose $(a^(n)) \subset S$ with $a^(n) \to a$ in $\ell^2$.  Suppose $a \not\in S$.   Then  $\sum_{j = 1}^N (1+j^2) |a_j|^2 > 1 + \epsilon$ for some $N$ and some $\epsilon > 0$.  But then we have
\begin{align*}
\epsilon & \le \sum_{j=1}^N (1 + j^2) |a_j|^2 - \sum_{j=1}^\infty (1+j)^2 |a^{(n)}_j|^2
\\ & \le \sum_{j=1}^N (1 + j^2) (|a_j|^2 - |a^{(n)}_j|^2)
\to 0
\end{align*}
as $n \to \infty$, a contradiction.  Hence $S$ is closed.

To see that $S$ is totally bounded, let $\epsilon > 0$.  We have $\sum_{j=N}^\infty |a_j|^2 \le N^{-2} \sum_{j=N}^\infty (1 + j^2) |a_j|^2 \le N^-2$ for $(a_j) \in \ell^2$.  Pick $N$ such that $N^-2 < \epsilon$.  Note that $\|a\| \le 1$ for all $a \in S$.  Recall that $B_1(\ell_2^N)$ is totally bounded.  The rest of $S$ is within $\epsilon$ of $B_1(\ell_2^N)$, so $S$ is totally bounded.
\end{proof}
\end{document}
