\documentclass{article}

\usepackage{../m}

\DeclareMathOperator{\Spec}{Spec}
\DeclareMathOperator{\slim}{s-lim}

\begin{document}
\noindent Paul Gustafson\\
\noindent MATH 663 - Subfactors, Knots, and Planar Algebras (Fall 2017)

\subsection*{HW 4}
\p 1 Let $(M, \tau)$ be a finite von Neumann algebra, let $1 \in N \subset M$ be a von Neumann subalgebra, and let $E: M \to N$ be the unique $\tau$-preserving conditional expectation.  Prove that $E$ is continuous and completely positive.

\begin{proof}
  The conditional expectation $E$ is a positive linear map between C-* algebras, so $E$ is bounded. Moreover, $E(x) = exe$ where $e:L^2(M) \to L^2(N)$ is the projection.  This implies that $E$ is completely positive (by the converse to Stinespring's theorem).
\end{proof}

\p 2 Let $\pi, \sigma \in NC_2(2n)$.  Let $\beta \in \CC \setminus \{0\}$ and consider the canonical trace $\tau : D_n(\beta) = TL_n(\beta^{-2}) \to \CC$.  Show that $\tau(D_\sigma^* D_\pi) = \beta^{|\pi \vee \sigma| - n}$.
\begin{proof}
  Write down the diagram for $D_\sigma^* D_\pi$ as the vertical concatenation of its two factor diagrams.  Label points on the boundary of $D_\pi$ by $1, \ldots, 2n$ in the usual way as if $D_\sigma^*$ was not there.  Label the $D_\sigma^*$ part according to the usual $D_\sigma$ labelling, i.e. reflect the usual $D_\sigma^*$ labelling through its horizontal midline. The $\sigma$-labels $n+1$ through $2n$ should agree with the $\pi$-labels. Moreover, the ``braid closure'' of $D_\sigma^* D_\pi$ connects the points labeled $1$ to $n$ for $\pi$ to the correspondingly labeled points for $\sigma$.  Thus, the connected components of the braid closure correspond to the blocks of $\sigma \vee \pi$. 
\end{proof}


\p 3 Prove that the canonical trace $\tau_n$ on $TL_n(\lambda)$ is positive semidefinite for all $\lambda \in (0, \frac{1}{4}]$.
  \begin{proof}
    Let $$\xi_\pi = \sum_{i \in \{1,2\}^{[2n]}} \prod_{\substack{r \sim_\pi s\\ r< s}} F_{i(s)i(r)} e_i,$$
      where $F = \beta^{-1/2} \begin{pmatrix} 0 & q^{-1} \\ q & 0 \end{pmatrix},$ and $\beta = q^2 + q^{-2}$ with $q \in \RR$.   We have
      \begin{align*}
        \langle \xi_\pi, \xi_\sigma \rangle & = \sum_i \prod_{\substack{r \sim_\pi s\\ r < s}} \prod_{\substack{t \sim_\sigma u\\ t < u}} F_{i(s)i(r)} F_{i(t) i(u)} 
        & = \sum_i \prod_{b \in \pi \vee \sigma} \prod_{\substack{r<s, t<u \in b\\ r \sim_\pi s \\ t \sim_\sigma u }} F_{i(s)i(r)} F_{i(t) i(u)} 
      \end{align*}

      Let $b$ be a block in $\pi \vee \sigma$, and let $x_1 \in [2n]$ be the minimal number in the block $b$.  Every element of $b$ is related to two other numbers by $\pi$ and $\sigma$ respectively, and the group generated by $\pi, \sigma \subset S_{2n}$ acts transitively on $b$.  Letting $x_{j+1} = \pi x_{j}$ if $j \ge 1$ is even and $x_{j+1} = \sigma x_j$ if $j \ge 1$ is odd, we have $b = \{x_j\}_{j = 1}^{|b|}$.  Thus,
      \begin{align*}
        \langle \xi_\pi, \xi_\sigma \rangle &  = \sum_i \prod_{b \in \pi \vee \sigma} \prod_{j = 1}^{|b|} F_{i(x_j)i(x_{j+1})}  
      \end{align*}

      For the last product to be nonvanishing, we must have $i(x_{j+1}) \neq i(x_{j})$ for all $j$.  Thus, for every block we get exactly two nonvanishing values of $i$ corresponding to the values $i(x_1)$ at the block's minimal element $x_1$.  Moreover, the map $j \mapsto x_j$ for $1 \le j \le |b| + 1$ defines a piecewise linear map $\phi: (1, |b| +1) \to \RR_{\ge 0}$ by connecting consecutive points with line segments.  It is easy to check that
      $$ \prod_{j = 1}^{|b|} F_{i(x_j)i(x_{j+1})}   = \beta^{\frac{-|b|}{2}} q^{\# (\text{local maxima of } \phi)- \# (\text{local minima of } \phi)} $$
      if $i(x_1) = 1$.  If $i(x_1) = 2$, the sign of the exponent of $q$ flips.   Since $x_1 = x_{|b| + 1}$ is minimal, the first and last local extrema of $\phi$ in $(1, |b| + 1)$ are local maxima.  Thus, the previous product is $q^2$ or $q^{-2}$, depending on $i(x_1)$.  Since the choice of $i(x_1)$ is independent for each block $b$, we have
\begin{align*}
  \langle \xi_\pi, \xi_\sigma \rangle &  = \prod_{b \in \pi \vee \sigma} \beta^{\frac{-|b|}{2}} (q^2 + q^{-2})   \\
  & = \beta^{-n} \prod_{b \in \pi \vee \sigma} \beta
  & = \beta^{|\pi \vee \sigma| - n}
\end{align*}

Thus, the Gram matrix for $\tau_n$ wrt to $(D_\pi)_\pi$ is same as the Gram matrix for the vectors $(\xi_\pi)_\pi$. Thus, $\tau_n$ is positive semidefinite.
\end{proof}
  
  \p {Exercise 10 of Speicher} Let $p,q \in B(H)$ be orthogonal projections on a separable complex Hilbert space $H$.
  \begin{enumerate}[(a)]
  \item Show that
    $$\slim_{n \to \infty} (pqp)^n = p \wedge q.$$
    \begin{proof}
      Since $pqp$ is self-adjoint, $C^*(1, pqp)$ is a unital commutative $C^*$-algebra, hence isometrically $*$-isomorphic to $C(\Spec(pqp))$ via a map $\phi$ with $\phi(pqp) = \id_{\Spec(pqp)}$.  It is easy to check that $pqp$ is a contractive positive operator. Hence, $\Spec(pqp) \subset [0,1]$.  Thus, $\phi((pqp)^n) = \id_{\Spec(pqp)}^n \to \chi_{\{1\}}$ strongly.  Thus, $(pqp)^n$ converges strongly to some projection $e$.

      %%FIXME ^^^^ (strongly)

      We have $pe = \lim_n p (pqp)^n = e$, so $p \le e$.  We also have, for all $\xi \in H$,
      \begin{align*}
        eqe \xi & = \lim_n (pqp)^n q \lim_m (pqp)^m \xi  \\
        & = \lim_n \lim_m (pqp)^n q (pqp)^m \xi \\
        & = \lim_{n} \lim_m (pqp)^{n + m + 1} \xi \
        & = \lim_n e \xi \\
        & = e \xi.
      \end{align*}
      Thus, for all $\xi \in H$,
      \begin{align*}
        \langle (e - q)\xi,  \xi \rangle & = \langle (e^2 - eqe) \xi,  \xi \rangle \\
        & = \langle (1 - q) e \xi, e \xi \rangle \\
        & \ge 0,
      \end{align*}
      so $q \le e$.  Thus, $p \wedge q \le e$

      On the other hand, $(p \wedge q) e \xi = \lim_n (p \wedge q) (pqp)^n \xi = \lim_n (p \wedge q) \xi = p \wedge q \xi$.  Thus,
      $e \le p \wedge q$.  Thus, $e = p \wedge q$.
    \end{proof}

  \item Deduce that $\slim_{n \to \infty} (pq)^n = p \wedge q$.
    \begin{proof}
      We have $(pq)^n \xi = (pqp)^{n-1}q \xi \to (p \wedge q) q \xi = p \wedge q \xi$ for all $\xi \in H$.
    \end{proof}

  \item Discuss the statements (a) and (b) in the case $H = \CC^3$ for the projections
    $p = \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0   \end{pmatrix}$
    and $q = u  \begin{pmatrix} 1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0   \end{pmatrix} u^*$, where $u = \begin{pmatrix} \cos(\theta) & 0 & -\sin(\theta) \\    0 & 1 & 0 \\      \sin(\theta) & 0 & \cos(\theta)     \end{pmatrix}$ for some
    $0 \le \theta \le \pi$.

    \emph{Answer:}
    
    The matrix $u$ is a rotation by $\theta$ about the $y$ axis. The matrix $q$ is a projection onto the space spanned by the $y$ axis and rotation of the $x$-axis by $\theta$ around the $y$-axis.  The matrix $p$ projects back onto the $x$ and $y$ axis.  Each time you do this the $x$-coordinate shrinks by a value of $\cos^2(\theta)$, but the $y$ coordinate remains the same.

    More explicitly, we have
    $(pq)^n = \begin{pmatrix} \cos(\theta)^{2n} & 0 & \cos(\theta)^{2n-1} \sin(\theta) \\ 0 & 1 & 0 \\ 0 & 0 & 0     \end{pmatrix}$ and
    $(pqp)^n = \begin{pmatrix} \cos(\theta)^{2n} & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 0     \end{pmatrix}$.

    The limit in both cases is the projection onto the $y$-axis.

  \end{enumerate}
    
  \p{Exercise 11 of Speicher} Let $(S_n)_{n=0}^\infty$ be the sequence of Chebyshev polynomials of the second kind, which are recursively defined by $S_0(x) = 1$, $S_1(x) = x$ and
  $$x S_n(x) = S_{n+1}(x) + S_{n-1}(x) \qquad \text{for all } n \ge 1.$$
  Prove the following statements.
  \begin{enumerate}[(a)]
  \item  For all $n \ge 0$ and all $0 < \theta < \pi$, it holds true that
    $$S_n( 2 \cos(\theta)) = \frac{\sin((n+1) \theta)}{\sin(\theta)}.$$
    \begin{proof}
      The base cases $n = 0,1$ are easy to check.  The inductive step reduces to
      checking the identity
      $$\sin((n+2) \theta) = 2 \cos(\theta) \sin((n+1) \theta) - \sin(n \theta).$$
      Letting $q = e^{i \theta}$, this reduces to checking
      $$ q^{n+2} - q^{-(n+2)} = (q + q^{-1}) (q^{n+1} - q^{-(n+1)}) - (q^{n} - q^{-n}).$$
    \end{proof}

  \item We have for all $n, m \ge 0$ that
    $$ \int_{-2}^2 S_n(x) S_m(x) \frac{1}{2\pi}  \sqrt{4 - x^2} \, dx = \delta_{n,m}. $$
    \begin{proof}
      We have
      \begin{align*}
        & \int_{-2}^2 S_n(x) S_m(x) \frac{1}{2\pi}  \sqrt{4 - x^2} \, dx \\
        & = \frac{2}{\pi}\int_{0}^\pi S_n(2 \cos(\theta)) S_m(2 \cos(\theta)) \sin^2(\theta) \, d \theta   \\
        & = \frac{2}{\pi} \int_{0}^\pi {\sin((n+1)\theta) \sin((m+1)\theta)} \, d \theta \\
        & = \frac{1}{\pi} \int_{-\pi}^\pi {\sin((n+1)\theta) \sin((m+1)\theta)} \, d \theta \\
        & = -\frac{1}{4\pi} \int_{-\pi}^\pi  (e^{i(n+1) \theta} - e^{-i(n+1) \theta}) (e^{i(m+1) \theta} - e^{-i(m+1) \theta})\, d \theta, \\
        & = -\frac{1}{4\pi} \int_{-\pi}^\pi  e^{i(m-n)\theta} + e^{i(n-m) \theta}\, d \theta,
        & = \delta_{nm},
      \end{align*}
      using the fact that $\frac{1}{2\pi} \int_{-\pi}^\pi e^{-ik\theta} \, d\theta = \delta_{0k}$ for all integers $k$.      
    \end{proof}
  \item For all $x \in [-2, 2]$ and all $z \in \CC$ with $|z| < 1$, we have
    $$ \frac{1}{1 - xz + z^2}  = \sum_{n=0}^\infty S_n(x) z^n$$
    \begin{proof}
      The function $f(z) = 1 - xz + z^2$ has roots at
      $\frac{x \pm \sqrt{x^2 - 4}}{2}$.  For $x \in [-2,2]$, we have
      $\left| \frac{x \pm \sqrt{x^2 - 4}}{2} \right|^2 = \frac{1}{4} \left(x^2      + (4- x^2) \right) = 1$.  Thus,  the power series for $f$ centered at $z = 0$ has radius of convergence $1$.

      Letting $x = 2 \cos(\theta)$, we have
      \begin{align*}
        \sum_{n=0}^\infty S_n(x) z^n & = \sum_{n=0}^\infty \frac{\sin((n+1) \theta)}{\sin{\theta}} z^n \\
        & =  \frac{1}{2i \sin(\theta)} \sum_{n=0}^\infty (e^{in\theta} - e^{-in\theta}) z^n \\
        & =  \frac{1}{2i \sin(\theta)} \sum_{n=0}^\infty (e^{i \theta}z)^n - (e^{-i \theta}z)^n \\
        & =  \frac{1}{2i \sin(\theta)} \left(\frac{1}{1 - (e^{i \theta}z)} - \frac{1}{1 -  (e^{-i \theta}z)} \right) \\
        & =  \frac{1}{2i \sin(\theta)} \left(\frac{2i\sin(\theta)}{1 -  2\cos(\theta)z + z^2} \right)\\
        & = \frac{1}{1 - xz + z^2}.
      \end{align*}
    \end{proof}

  \item For $x, y \in [-2,2]$ and all $n \ge 0$, we have
    $$\frac{S_n(x) - S_n(y)}{x - y} = \sum_{k = 1}^n S_{k-1}(x) S_{n-k}(y).$$
    
    \begin{proof}
      We have
      \begin{align*}
        \sum_{n = 0}^\infty {S_n(x) - S_n(y)}{x - y} z^n & = \frac{1}{x-y} \left( \frac{1}{1 - xz + z^2} - \frac{1}{1 - yz + z^2} \right) \\
        & = \frac{1}{x-y}\left(\frac{(x - y)z}{(1 - xz + z^2) (1 - yz + z^2)}\right) \\
        & = z \left( \sum_{n=0}^\infty S_n(x)z^n \right) \left(\sum_{n=0}^\infty S_n(y) z^n \right) \\
        & = z \sum_{n=0}^\infty \sum_{k = 0}^n S_k(x) S_{n-k}(y) z^n) \\
        & = \sum_{n=0}^\infty \sum_{k = 1}^{n+1} S_{k-1}(x) S_{n-k+1}(y) z^{n+1}) \\
        & = \sum_{n=0}^\infty \sum_{k = 1}^{n} S_{k-1}(x) S_{n-k}(y) z^{n})
      \end{align*}
    \end{proof}
  \end{enumerate}


\end{document}
